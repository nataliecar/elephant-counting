{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nataliecar/elephant-counting/blob/main/STITCH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIOw-yZ1bt8W"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "def resize_image(image, target_size):\n",
        "    return cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "def image_stitching(image_folder, output_folder, target_size=(2446, 3669)):\n",
        "    print(f\"Input folder: {image_folder}\")\n",
        "    print(f\"Output folder: {output_folder}\")\n",
        "\n",
        "    # Get a list of all image files in the folder\n",
        "    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "    image_files.reverse()\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Iterate through each image in the folder\n",
        "    for i, image_file in enumerate(image_files):\n",
        "        # Read the current image\n",
        "        current_image = cv2.imread(os.path.join(image_folder, image_file))\n",
        "\n",
        "        print(f\"Processing {image_file} - Type: {current_image.dtype}, Shape: {current_image.shape}\")\n",
        "\n",
        "        # Resize the image to the target size\n",
        "        current_image = resize_image(current_image, target_size)\n",
        "\n",
        "        # Initialize the stitched image for the current image\n",
        "        stitched_image = current_image.copy()\n",
        "\n",
        "        # Iterate through each other image in the folder\n",
        "        for j, other_image_file in enumerate(image_files):\n",
        "            if i != j:  # Skip comparing the image with itself\n",
        "                # Read the other image\n",
        "                other_image = cv2.imread(os.path.join(image_folder, other_image_file))\n",
        "\n",
        "                # Resize the other image to the target size\n",
        "                other_image = resize_image(other_image, target_size)\n",
        "\n",
        "                # Check if the images have the same data type and number of columns\n",
        "                if current_image.dtype != other_image.dtype or current_image.shape[1] != other_image.shape[1]:\n",
        "                    print(f\"Skipping {other_image_file} due to data type or dimension mismatch.\")\n",
        "                    print(f\"Current Image Type: {current_image.dtype}, Shape: {current_image.shape}\")\n",
        "                    print(f\"Other Image Type: {other_image.dtype}, Shape: {other_image.shape}\")\n",
        "                    continue\n",
        "\n",
        "                # Find the keypoints and descriptors with ORB\n",
        "                orb = cv2.ORB_create()\n",
        "                kp1, des1 = orb.detectAndCompute(stitched_image, None)\n",
        "                kp2, des2 = orb.detectAndCompute(other_image, None)\n",
        "\n",
        "                # Use BFMatcher to find the best matches between descriptors\n",
        "                bf = cv2.BFMatcher()\n",
        "                matches = bf.knnMatch(des1, des2, k=2)\n",
        "\n",
        "                # Apply ratio test\n",
        "                good_matches = []\n",
        "                for m, n in matches:\n",
        "                    if m.distance < 0.6 * n.distance:\n",
        "                        good_matches.append(m)\n",
        "\n",
        "                # If enough good matches are found, stitch the images\n",
        "                if len(good_matches) > 10:\n",
        "                    src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "                    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "\n",
        "                    M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "\n",
        "                    # Ensure stitched_image has the correct dimensions\n",
        "                    stitched_image = cv2.warpPerspective(stitched_image, M, (other_image.shape[1], other_image.shape[0]))\n",
        "\n",
        "                    stitched_image[0:other_image.shape[0], 0:other_image.shape[1]] = other_image\n",
        "\n",
        "                    print(f\"Stitched {image_file} with {other_image_file} - Matches: {len(good_matches)}\")\n",
        "\n",
        "        # Save the stitched image for the current image\n",
        "        output_path = os.path.join(output_folder, f\"stitched_{image_file}\")\n",
        "        cv2.imwrite(output_path, stitched_image.copy())  # Save a copy of the stitched image\n",
        "\n",
        "    print(\"Image stitching completed.\")\n",
        "\n",
        "input_folder = '/content/drive/My Drive/AED/test_gsd/'\n",
        "output_folder = '/content/drive/My Drive/Test_STITCH2/'\n",
        "image_stitching(input_folder, output_folder)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNXibHsC62YY37acwEldPHj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
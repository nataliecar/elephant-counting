{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e92bbdcf-eec4-4fef-b1dd-dd1c4a04c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf246a6a-9429-4635-9c1e-fb9c03e6a0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  image name     x     y\n",
      "0   2aada86263161acc6e207ea329759556d308458a   502     2\n",
      "1   8f30778719e5af075797f994273603c94f170e29    78   176\n",
      "2   8f30778719e5af075797f994273603c94f170e29   844  2436\n",
      "3   8f30778719e5af075797f994273603c94f170e29   794  2468\n",
      "4   8f30778719e5af075797f994273603c94f170e29   687  2432\n",
      "..                                       ...   ...   ...\n",
      "67  8b1a6dead4e015f168627d466b5eab09aedbf90d  1785   423\n",
      "68  8b1a6dead4e015f168627d466b5eab09aedbf90d  1303    18\n",
      "69  8b1a6dead4e015f168627d466b5eab09aedbf90d  1825   425\n",
      "70  8b1a6dead4e015f168627d466b5eab09aedbf90d  1779   452\n",
      "71  8b1a6dead4e015f168627d466b5eab09aedbf90d  1680   505\n",
      "\n",
      "[72 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Change these paths\n",
    "elephants_csv = 'sample_elephants_new.csv'\n",
    "df_elephants = pd.read_csv(elephants_csv)\n",
    "images = 'sample_images/'\n",
    "output = 'sample_bbox_images/'\n",
    "print(df_elephants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dbeea91-045b-4b9c-bfda-954778132195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accumulate rows for new elephants dataframe\n",
    "data = [] \n",
    "\n",
    "#Loop through each image\n",
    "for image_name in df_elephants['image name'].unique():\n",
    "    #Get the a dataframe that has all rows with this image\n",
    "    df_image = df_elephants[df_elephants['image name'] == image_name]\n",
    "\n",
    "    #Load image\n",
    "    image_path = f'{images}{image_name}.jpg'\n",
    "    img = Image.open(image_path) #use PIL to open image so we can save metadata\n",
    "    metadata = img.getexif()\n",
    "    #img = read_image(image_path)\n",
    "    img = torchvision.transforms.functional.pil_to_tensor(img)\n",
    "\n",
    "    #List of bboxes\n",
    "    bboxes = []\n",
    "\n",
    "    #Loop through each elephant in current image to create bboxes\n",
    "    for index, row in df_image.iterrows():\n",
    "        #Calculate bbox coordinates assuming x, y is center of elephant\n",
    "        x = row['x']\n",
    "        y = row['y']\n",
    "        width = 25\n",
    "        height = 25\n",
    "        x_tl = int(x - width / 2)\n",
    "        y_tl = int(y - height / 2)\n",
    "        x_br = int(x + width / 2)\n",
    "        y_br = int(y + height / 2)\n",
    "\n",
    "        bbox = [x_tl, y_tl, x_br, y_br]\n",
    "        bboxes.append(bbox)\n",
    "\n",
    "        data.append({'image name': image_name, 'xmin': x_tl, 'ymin': y_tl, 'xmax': x_br, 'ymax': y_br})\n",
    "\n",
    "    #Draw the bboxes\n",
    "    bboxes = torch.tensor(bboxes, dtype=torch.int)\n",
    "    img = draw_bounding_boxes(img, bboxes, width=1, colors=\"red\")\n",
    "    \n",
    "    #Save the image with bboxes\n",
    "    img = torchvision.transforms.ToPILImage()(img)\n",
    "    output_path = f'{output}{image_name}.jpg'\n",
    "    img.save(output_path, exif=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dca5f357-22a1-42b5-a217-5d061f54209f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  image name  xmin  ymin  xmax  ymax\n",
      "0   2aada86263161acc6e207ea329759556d308458a   489   -10   514    14\n",
      "1   8f30778719e5af075797f994273603c94f170e29    65   163    90   188\n",
      "2   8f30778719e5af075797f994273603c94f170e29   831  2423   856  2448\n",
      "3   8f30778719e5af075797f994273603c94f170e29   781  2455   806  2480\n",
      "4   8f30778719e5af075797f994273603c94f170e29   674  2419   699  2444\n",
      "..                                       ...   ...   ...   ...   ...\n",
      "67  8b1a6dead4e015f168627d466b5eab09aedbf90d  1772   410  1797   435\n",
      "68  8b1a6dead4e015f168627d466b5eab09aedbf90d  1290     5  1315    30\n",
      "69  8b1a6dead4e015f168627d466b5eab09aedbf90d  1812   412  1837   437\n",
      "70  8b1a6dead4e015f168627d466b5eab09aedbf90d  1766   439  1791   464\n",
      "71  8b1a6dead4e015f168627d466b5eab09aedbf90d  1667   492  1692   517\n",
      "\n",
      "[72 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create new elephants dataframe and output to csv file\n",
    "df_elephants_new = pd.DataFrame(data)\n",
    "print(df_elephants_new)\n",
    "\n",
    "filename = 'sample_elephants_bbox.csv' #Change this filename\n",
    "df_elephants_new.to_csv(filename, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade9cca-a80d-44fd-a9a0-5135dd1e35ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

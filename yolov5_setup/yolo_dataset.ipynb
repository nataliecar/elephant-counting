{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537cd0c8-98d2-4b7b-bdfb-8338fbb9e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e7ff364-53a1-4d8a-8da6-f0a7a7f52dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    image name     x     y\n",
      "0     7d4d55723d3f6b8f174a88d36fc493d0b7fb6fc3  1719   592\n",
      "1     04f53ca293e5037fc04f61e49b372d8f003c482d  1375  1226\n",
      "2     04f53ca293e5037fc04f61e49b372d8f003c482d  1796   319\n",
      "3     884fa549d6eaaf243d9db96bca0382f9068af146   946   777\n",
      "4     884fa549d6eaaf243d9db96bca0382f9068af146   952   799\n",
      "...                                        ...   ...   ...\n",
      "2965  c8f33a304bd04467f40271ca2cf1bf011128f196   710   901\n",
      "2966  69fab1105c5709822edd34975aa0faaa5d922866   901  1174\n",
      "2967  69fab1105c5709822edd34975aa0faaa5d922866   845  1420\n",
      "2968  69fab1105c5709822edd34975aa0faaa5d922866   871  1119\n",
      "2969  69fab1105c5709822edd34975aa0faaa5d922866   908  1074\n",
      "\n",
      "[2970 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Change these file paths depending if your generating training or test labels\n",
    "elephants_csv = 'datasets/AED_gsd/test_elephants_new.csv'\n",
    "df_elephants = pd.read_csv(elephants_csv)\n",
    "images = 'datasets/AED_gsd/images/test_images_bbox/'\n",
    "output = 'datasets/AED_gsd/labels/test_images_bbox/'\n",
    "print(df_elephants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "381bb802-225f-425b-8c1e-d619096376a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through each image\n",
    "for image_name in df_elephants['image name'].unique():\n",
    "    #Accumulate rows for each image\n",
    "    data = []\n",
    "    \n",
    "    #Get the a dataframe that has all rows with this image\n",
    "    df_image = df_elephants[df_elephants['image name'] == image_name]\n",
    "\n",
    "    #Load image (so we can get image dimensions)\n",
    "    image_path = f'{images}{image_name}.jpg'\n",
    "    img = Image.open(image_path) #use PIL to open image\n",
    "    img_width, img_height = img.size\n",
    "\n",
    "    #Loop through each elephant in current image\n",
    "    for index, row in df_image.iterrows():\n",
    "        #Calculate normalized bbox coordinates for yolo\n",
    "        \n",
    "        #THIS WILL NEED TO BE CHANGED IF USING CANNY DETECTION\n",
    "        #Rather than using the elephants csv file that is image, x, y. You would use the canny detection csv file and convert\n",
    "        #the bbox coordinates given there to the format yolo wants\n",
    "        \n",
    "        x = row['x']\n",
    "        y = row['y']\n",
    "        width = 25\n",
    "        height = 25\n",
    "\n",
    "        x_center = x/img_width\n",
    "        y_center = y/img_height\n",
    "        norm_width = width/img_width\n",
    "        norm_height = height/img_height\n",
    "\n",
    "        if(x_center > 1):\n",
    "            x_center = 1\n",
    "        if(y_center > 1):\n",
    "            y_center = 1\n",
    "\n",
    "        data.append({'class': 0, 'x_center': x_center, 'y_center': y_center, 'width': norm_width, 'height': norm_height})\n",
    "        \n",
    "    #Output to txt file\n",
    "    df_data = pd.DataFrame(data)\n",
    "    #print(df_data)\n",
    "    \n",
    "    filename = output + image_name + '.txt'\n",
    "    df_data.to_csv(filename, sep='\\t', index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb044fac-64fc-461b-9873-4e12ff73980d",
   "metadata": {},
   "source": [
    "Instructions for running yolov5 on our dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1ad35-6cd8-4ece-80f4-39cefcad9bfe",
   "metadata": {},
   "source": [
    "1. Download yolov5 by running these commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cea988d-6db1-4d56-9a0c-a5187681369d",
   "metadata": {},
   "source": [
    "git clone https://github.com/ultralytics/yolov5\n",
    "   \n",
    "cd yolov5\n",
    "   \n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c9ea0-98d1-49a5-90bd-5fa50fbfac02",
   "metadata": {},
   "source": [
    "This creates a directory called yolov5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3871230-6422-4c7e-9f8f-d70f90f520cd",
   "metadata": {},
   "source": [
    "2. In the same directory that you installed the yolov5 directory, create a new directory called datasets.\n",
    "  \n",
    "   In this directory, create another directory called AED_gsd.\n",
    "\n",
    "   In the AED_gsd directory, create two new directories called images and labels.\n",
    "\n",
    "   Put the 2 folders containing the training_images and test_images (the ones with consistent GSD) into the images directory\n",
    "\n",
    "   Use the code in this notebook to generate labels for the both the training_images and test_images. The folders within labels that contain the labels need to be named the same thing as the folders that contain the images. Just put this notebook in the same directory where the yolov5 and datasets directories are contained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e1969-1c26-4125-acf8-c7f9097a8e3c",
   "metadata": {},
   "source": [
    "3. Put the provided AED.yaml and AED_test.yaml files into the data folder within the yolov5 directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833637ee-d582-4066-a00c-1bd1afb54475",
   "metadata": {},
   "source": [
    "4. Run these commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6c3ffc-ea77-405f-b56f-d4ed73df79e3",
   "metadata": {},
   "source": [
    "python train.py --img 640 --epochs 300 --batch-size 8 --data AED.yaml --weights yolov5n.pt\n",
    "\n",
    "python val.py --img 640 --weights runs/train/exp10/weights/best.pt --data AED_test.yaml\n",
    "\n",
    "python detect.py --source ../datasets/AED_gsd/images/test_images/ --weights runs/train/exp10/weights/best.pt --img 640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe560d-1e48-4987-87e2-e94d54e87fe5",
   "metadata": {},
   "source": [
    "The first command trains the model. Depending on your PC, you can up the batch size, up the img size (1280), and use the bigger pretrained models (weights). The results are saved in yolov5/runs/train/exp# (exp# is just the most recent run). This also takes like 15 hours probably.\n",
    "\n",
    "The second command will test the model and see how well it performs. The results are saved in yolov5/runs/val/exp#.\n",
    "\n",
    "The third command will actually try to detect the elephants in the test images using the trained model. This outputs all the images into yolov5/runs/detect/exp# with the detected bounding boxes. You can change what it outputs and saves using command line args that you can find in detect.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9de0d1-6f9c-4e1b-a7c9-31689516dd04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
